# Resources and References

This directory contains curated resources, references, and supplementary materials for the LLM in Scientific Papers course.

## üìö Essential Papers

### Foundational Papers
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Vaswani et al., 2017
- [BERT: Pre-training of Deep Bidirectional Transformers](https://arxiv.org/abs/1810.04805) - Devlin et al., 2018
- [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) - Brown et al., 2020

### Scientific Domain Applications
- [SciBERT: A Pretrained Language Model for Scientific Text](https://arxiv.org/abs/1903.10676)
- [BioBERT: a pre-trained biomedical language representation model](https://arxiv.org/abs/1901.08746)
- [Scientific Language Models for Biomedical Knowledge Base Completion](https://arxiv.org/abs/2106.09700)

### Recent Advances
- [GPT-4 Technical Report](https://arxiv.org/abs/2303.08774)
- [Large Language Models in Scientific Discovery](https://arxiv.org/abs/2301.00810)
- [ChatGPT for Scientific Writing: A Cautionary Tale](https://arxiv.org/abs/2301.04550)

## üîó Online Resources

### Documentation and Tutorials
- [Hugging Face Transformers Documentation](https://huggingface.co/docs/transformers/index)
- [OpenAI API Documentation](https://platform.openai.com/docs)
- [Google AI Language Models](https://ai.google/research/language/)

### Datasets
- [Semantic Scholar Open Research Corpus](https://www.semanticscholar.org/corpus)
- [PubMed Central Open Access](https://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/)
- [arXiv Dataset](https://www.kaggle.com/Cornell-University/arxiv)

### Tools and Libraries
- [spaCy](https://spacy.io/) - Industrial-strength Natural Language Processing
- [NLTK](https://www.nltk.org/) - Natural Language Toolkit
- [Gensim](https://radimrehurek.com/gensim/) - Topic modeling and document similarity

## üìñ Books and Textbooks

### Machine Learning and NLP
- "Speech and Language Processing" by Jurafsky & Martin
- "Natural Language Processing with Python" by Bird, Klein & Loper
- "Deep Learning" by Goodfellow, Bengio & Courville

### Scientific Computing
- "Python for Data Analysis" by Wes McKinney
- "Hands-On Machine Learning" by Aur√©lien G√©ron
- "Pattern Recognition and Machine Learning" by Christopher Bishop

## üé• Video Resources

### Lecture Series
- Stanford CS224N: Natural Language Processing with Deep Learning
- MIT 6.034 Artificial Intelligence
- DeepLearning.AI Natural Language Processing Specialization

### Conference Talks
- NeurIPS talks on language models
- ACL conference presentations
- ICML workshops on scientific applications

## üõ†Ô∏è Software and Environments

### Development Environments
- [Google Colab](https://colab.research.google.com/) - Free GPU access
- [Jupyter Notebooks](https://jupyter.org/) - Interactive development
- [VS Code](https://code.visualstudio.com/) - Code editor with extensions

### Package Management
- [Anaconda](https://www.anaconda.com/) - Python distribution
- [pip](https://pip.pypa.io/) - Python package installer
- [Poetry](https://python-poetry.org/) - Dependency management

## üìä Evaluation Metrics and Benchmarks

### Language Model Evaluation
- BLEU, ROUGE, METEOR scores
- Perplexity and cross-entropy
- Human evaluation protocols

### Scientific Text Benchmarks
- SciERC (Scientific Information Extraction)
- SciFact (Scientific Claim Verification)
- MultiXScience (Multi-document summarization)

## üèõÔ∏è Research Groups and Labs

### Academic Institutions
- Allen Institute for AI (AI2)
- Google Research
- Microsoft Research
- Facebook AI Research (FAIR)

### Industry Research
- OpenAI
- Anthropic
- Cohere
- Hugging Face

## üì± Staying Updated

### Newsletters and Blogs
- [The Batch by DeepLearning.AI](https://www.deeplearning.ai/the-batch/)
- [Towards Data Science](https://towardsdatascience.com/)
- [Distill.pub](https://distill.pub/)

### Social Media and Communities
- [r/MachineLearning](https://www.reddit.com/r/MachineLearning/)
- [AI Twitter community](https://twitter.com/hashtag/artificialintelligence)
- [Papers With Code](https://paperswithcode.com/)

---

## üìã Contributing to Resources

To add new resources:
1. Verify the quality and relevance of the resource
2. Add it to the appropriate section
3. Include a brief description
4. Ensure links are working and accessible
5. Submit a pull request for review